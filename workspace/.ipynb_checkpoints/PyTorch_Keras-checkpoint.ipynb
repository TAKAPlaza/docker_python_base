{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c66a37-6aa6-4806-a9e2-1189e9d403a3",
   "metadata": {},
   "source": [
    "# SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a9e31-ab0e-412d-8286-41b0cc98dee6",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b02f6a8-93ab-4c2a-a0e2-576d1a2442a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.30852407217025757\n",
      "Epoch 2/10, Loss: 0.28075551986694336\n",
      "Epoch 3/10, Loss: 0.25569915771484375\n",
      "Epoch 4/10, Loss: 0.23372378945350647\n",
      "Epoch 5/10, Loss: 0.21310746669769287\n",
      "Epoch 6/10, Loss: 0.19393499195575714\n",
      "Epoch 7/10, Loss: 0.17595838010311127\n",
      "Epoch 8/10, Loss: 0.15946894884109497\n",
      "Epoch 9/10, Loss: 0.1438818871974945\n",
      "Epoch 10/10, Loss: 0.12958644330501556\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)  # 入力層\n",
    "        self.fc2 = nn.Linear(50, 50)  # 中間層\n",
    "        self.fc3 = nn.Linear(50, 1)   # 出力層\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # 回帰のための活性化関数は不要\n",
    "        return x\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = SimpleNet()\n",
    "\n",
    "# 損失関数とオプティマイザ\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ダミーデータ\n",
    "inputs = torch.randn(5, 10)\n",
    "targets = torch.randn(5, 1)\n",
    "\n",
    "# 訓練ループ\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d6f80-e386-41fd-a42b-477a1753f3a1",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e681196-0784-4382-bb85-57433c1f51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d04840-7b64-43cb-a60a-2a5f42230433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 2.6249\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4654\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3118\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1648\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0262\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8962\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7779\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6657\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5579\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe200041890>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(10,)),  # 入力層\n",
    "    Dense(50, activation='relu'),                      # 中間層\n",
    "    Dense(1)                                           # 出力層（回帰のため活性化関数なし）\n",
    "])\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# ダミーデータ\n",
    "import numpy as np\n",
    "inputs = np.random.randn(5, 10)\n",
    "targets = np.random.randn(5, 1)\n",
    "\n",
    "# 訓練\n",
    "model.fit(inputs, targets, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8386e9a-9020-4499-bd8d-a5fef07383be",
   "metadata": {},
   "source": [
    "# Dataset, Dataloder, loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f406ae6-851d-490c-a6a5-b4097ea7c352",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e98158-0cda-456f-93b7-9ec8069c2e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 1.0882259607315063\n",
      "Epoch 20/100, Loss: 1.0174328088760376\n",
      "Epoch 30/100, Loss: 0.9432248473167419\n",
      "Epoch 40/100, Loss: 0.8711585402488708\n",
      "Epoch 50/100, Loss: 0.7989201545715332\n",
      "Epoch 60/100, Loss: 0.7192288041114807\n",
      "Epoch 70/100, Loss: 0.6366647481918335\n",
      "Epoch 80/100, Loss: 0.5531353950500488\n",
      "Epoch 90/100, Loss: 0.4701494574546814\n",
      "Epoch 100/100, Loss: 0.3920566439628601\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)  # 入力層\n",
    "        self.fc2 = nn.Linear(50, 50)  # 中間層\n",
    "        self.fc3 = nn.Linear(50, 1)   # 出力層\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # 回帰のための活性化関数は不要\n",
    "        return x\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = SimpleNet()\n",
    "\n",
    "# 損失関数とオプティマイザ\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# カスタムDataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# ダミーデータの生成\n",
    "inputs = torch.randn(100, 10)  # 100個のデータポイント、各10の特徴\n",
    "targets = torch.randn(100, 1)  # 100個のターゲット値\n",
    "\n",
    "# データセットの作成\n",
    "dataset = CustomDataset(inputs, targets)\n",
    "\n",
    "# データローダーの初期化\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  # 10エポックごとに損失を出力\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44f844-7ae6-45b0-af0f-7fd6e5470485",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687e32d1-a27c-4d2d-8e34-fcd662939238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: {'loss': 0.08210927993059158}\n",
      "Epoch 20: {'loss': 0.061410948634147644}\n",
      "Epoch 30: {'loss': 0.04954029619693756}\n",
      "Epoch 40: {'loss': 0.03974573314189911}\n",
      "Epoch 50: {'loss': 0.03133746609091759}\n",
      "Epoch 60: {'loss': 0.023732054978609085}\n",
      "Epoch 70: {'loss': 0.01780017837882042}\n",
      "Epoch 80: {'loss': 0.012924125418066978}\n",
      "Epoch 90: {'loss': 0.009138758294284344}\n",
      "Epoch 100: {'loss': 0.006350496783852577}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9332c41d50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(10,)),  # 入力層\n",
    "    Dense(50, activation='relu'),                      # 中間層\n",
    "    Dense(1)                                           # 出力層（回帰のため活性化関数なし）\n",
    "])\n",
    "\n",
    "# サンプルデータ（Numpy配列）\n",
    "inputs = np.random.random((100, 32)).astype(np.float32)\n",
    "targets = np.random.random((100, 1)).astype(np.float32)\n",
    "\n",
    "# tf.data.Datasetの作成\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "# モデルの作成\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# カスタムコールバックの定義\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}: {logs}\")\n",
    "\n",
    "# 訓練\n",
    "model.fit(dataset, epochs=100, callbacks=[CustomCallback()], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac128f6-d352-41ae-beb2-4ae0a7ebe361",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f5492-1139-4c19-834e-d82fe0f9bd73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d135acb1-5141-476e-a1b3-7f4a08cd7246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1337\n",
      "Test Loss: 0.13373757898807526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "inputs = np.random.randomm((100, 32)).astype(np.float32)\n",
    "targets = np.random.random((100, 1)).astype(np.float32)\n",
    "\n",
    "# データをトレーニングセットとテストセットに分割\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size=0.3)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(32,)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.fit(inputs_train, targets_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# テストデータでモデルを評価\n",
    "loss = model.evaluate(inputs_test, targets_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e352c-ff05-4630-863f-741879e45524",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7022a5af-6c42-46c3-8b6b-e91abae9a2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0772658387819927\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# カスタムデータセットの定義\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# ダミーデータの生成\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randn(100, 1)\n",
    "\n",
    "# データセットの作成\n",
    "dataset = CustomDataset(inputs, targets)\n",
    "\n",
    "# データセットをトレーニングセットとテストセットに分割\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# モデルの定義\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet()\n",
    "\n",
    "# 損失関数とオプティマイザ\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# データローダー\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# トレーニング\n",
    "for epoch in range(100):\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# テスト\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0f8db-f5c2-468b-9923-d9e8a9f74d50",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0c424-2d1b-4e30-a47a-80867aea3d0f",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb30f486-9e96-4feb-bd9f-3431b685840b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder4): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (final_layer): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder部分の定義\n",
    "        self.encoder1 = self.contracting_block(1, 64)\n",
    "        self.encoder2 = self.contracting_block(64, 128)\n",
    "        self.encoder3 = self.contracting_block(128, 256)\n",
    "        self.encoder4 = self.contracting_block(256, 512)\n",
    "\n",
    "        # Bottleneck部分の定義\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024, 1024, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Decoder部分の定義\n",
    "        self.decoder1 = self.expansive_block(1024, 512, 512)\n",
    "        self.decoder2 = self.expansive_block(512, 256, 256)\n",
    "        self.decoder3 = self.expansive_block(256, 128, 128)\n",
    "        self.decoder4 = self.expansive_block(128, 64, 64)\n",
    "\n",
    "        # 出力層の定義\n",
    "        self.final_layer = nn.Conv2d(64, 2, 1)\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channel, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(mid_channel, out_channels, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoderの順伝播\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "\n",
    "        # Bottleneckの順伝播\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "\n",
    "        # Decoderの順伝播\n",
    "        dec1 = self.decoder1(torch.cat((self.upsample(bottleneck), enc4), 1))\n",
    "        dec2 = self.decoder2(torch.cat((self.upsample(dec1), enc3), 1))\n",
    "        dec3 = self.decoder3(torch.cat((self.upsample(dec2), enc2), 1))\n",
    "        dec4 = self.decoder4(torch.cat((self.upsample(dec3), enc1), 1))\n",
    "        \n",
    "        # 最終層\n",
    "        return self.final_layer(dec4)\n",
    "\n",
    "    def pool(self, x):\n",
    "        return nn.MaxPool2d(2)(x)\n",
    "\n",
    "    def upsample(self, x):\n",
    "        return nn.ConvTranspose2d(x.size(1), x.size(1), 2, stride=2)(x)\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = UNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c298a6-e1c8-4c68-ab4a-ea46676c8e52",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80148fb-38d1-48e1-a71c-392842201f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 128, 128, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)  0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 64, 128)  147584      ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0          ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 32, 32, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 32, 32, 256)  590080      ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0          ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 512)  2359808     ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)   0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 8, 8, 1024)   9438208     ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1024  0          ['conv2d_28[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 1536  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 512)  7078400     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 512)  2359808     ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 512)  0          ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 768)  0           ['up_sampling2d_5[0][0]',        \n",
      "                                                                  'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 256)  1769728     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 32, 256)  590080      ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 256)  0          ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 384)  0           ['up_sampling2d_6[0][0]',        \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 64, 64, 128)  442496      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 64, 64, 128)  147584      ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 12  0          ['conv2d_34[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 128, 128, 19  0           ['up_sampling2d_7[0][0]',        \n",
      "                                2)                                'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 128, 64  110656      ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_35[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 128, 128, 1)  65          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,378,945\n",
      "Trainable params: 31,378,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    tensor = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(input_tensor)\n",
    "    tensor = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(tensor)\n",
    "    return tensor\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "    return encoder, encoder_pool\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = UpSampling2D((2, 2))(input_tensor)\n",
    "    decoder = concatenate([decoder, concat_tensor], axis=-1)\n",
    "    decoder = conv_block(decoder, num_filters)\n",
    "    return decoder\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    encoder1, encoder_pool1 = encoder_block(inputs, 64)\n",
    "    encoder2, encoder_pool2 = encoder_block(encoder_pool1, 128)\n",
    "    encoder3, encoder_pool3 = encoder_block(encoder_pool2, 256)\n",
    "    encoder4, encoder_pool4 = encoder_block(encoder_pool3, 512)\n",
    "\n",
    "    # Center\n",
    "    center = conv_block(encoder_pool4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    decoder4 = decoder_block(center, encoder4, 512)\n",
    "    decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "    decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "    decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(decoder1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# モデルの構築\n",
    "input_shape = (128, 128, 3)  # 例として128x128のRGB画像を想定\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdbe18-a7b4-47dd-8fe7-d77282b9cd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c34b5-cf2d-4637-b208-537312547ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
